# SVA - Smart Video Assistant ğŸ¬

A fully local AI desktop application that analyzes and queries short video files completely offline. No internet connection required!

## ğŸŒŸ Features

- **ğŸ¤ Speech-to-Text**: Extract spoken content with HuggingFace Whisper
- **ğŸ‘ï¸ Visual Text Recognition**: Detect and extract on-screen text with TrOCR
- **ğŸ¯ Object Detection**: Identify objects using DETR models
- **ğŸ“Š Content Analysis**: Intelligent thematic analysis and summarization
- **ğŸ“„ Report Generation**: Professional PDF, PowerPoint, and text reports
- **ğŸ’» Desktop Interface**: Modern chat-based UI built with Tauri + React
- **ğŸ”’ Fully Offline**: All processing happens locally with no internet dependency

## ğŸ“‹ Requirements

### System Requirements
- **OS**: Linux, macOS, or Windows
- **RAM**: Minimum 8GB (16GB recommended for better performance)
- **Storage**: 5GB free space for models and dependencies
- **CPU**: Multi-core processor recommended for faster analysis

### Software Prerequisites
- **Python**: 3.10 or higher
- **Node.js**: 16.x or higher
- **Rust**: Latest stable version (for Tauri)
- **FFmpeg**: For video processing

## ğŸš€ Installation & Setup

### 1. Clone the Repository
```bash
git clone https://github.com/KhairulIzwan/SVA.git
cd SVA
```

### 2. Backend Setup (Python + AI Models)
```bash
# Create Python virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install Python dependencies
pip install -r requirements.txt

# Install additional report generation libraries
pip install reportlab python-pptx

# Test backend setup
cd backend
python test_setup.py
```

### 3. Frontend Setup (Tauri + React)
```bash
cd frontend

# Install Node.js dependencies
npm install

# Install Tauri CLI (if not already installed)
npm install -g @tauri-apps/cli

# Build frontend
npm run build
```

### 4. Install System Dependencies

#### Ubuntu/Debian:
```bash
sudo apt update
sudo apt install ffmpeg build-essential pkg-config libssl-dev
```

#### macOS:
```bash
brew install ffmpeg
```

#### Windows:
- Download FFmpeg from https://ffmpeg.org/download.html
- Add FFmpeg to your system PATH

## ğŸ¯ Quick Start

### Option 1: Development Mode
```bash
# Terminal 1: Start backend server
cd backend
source ../venv/bin/activate
python grpc_server_fixed_new.py

# Terminal 2: Start frontend
cd frontend
npm run tauri dev
```

### Option 2: Production Build
```bash
# Build the complete application
cd frontend
npm run tauri build

# Run the built application
# The executable will be in src-tauri/target/release/
```

## ğŸ“– Usage Guide

### 1. **Upload Video**
- Click "Upload Video" in the chat interface
- Select a video file (MP4, AVI, MOV supported)
- Maximum recommended duration: 2-3 minutes for optimal performance

### 2. **Ask Questions**
Use natural language to query your video:

- **"Extract all text from this video"** - Gets spoken and visual text
- **"What objects can you see?"** - Detects and lists objects
- **"Analyze this presentation"** - Comprehensive analysis
- **"Transcribe the speech"** - Audio-to-text conversion only
- **"What's written on screen?"** - Visual text recognition only

### 3. **Generate Reports**
After analysis, use the report buttons:
- **ğŸ“„ PDF Report**: Professional formatted report
- **ğŸ“Š PowerPoint**: Presentation-ready slides
- **ğŸ“ Text Report**: Simple text summary

### 4. **View Results**
- Analysis appears in real-time in the chat
- Reports are saved to `backend/generated_reports/`
- All conversations are preserved in `backend/chat_storage/`

## ğŸ“š Examples & Sample Outputs

### ğŸ“¹ **Example Input Files**

We provide sample videos to help you test SVA's capabilities:

#### ğŸ¥ **Sample Test Video**
![SVA Analysis Demo](sva_demo.gif)

**Included Test Files:**
```bash
data/videos/
â”œâ”€â”€ test_video.mp4          # Main demo video (30s business presentation)
â””â”€â”€ sample_video           # Additional test content
```

### ğŸ’¬ **Sample Queries & Responses**

![SVA Chat Interface](https://github.com/KhairulIzwan/SVA/blob/main/Screenshot%202025-10-17%20093237.png)

*Example of SVA's chat interface showing real video analysis results*

### ğŸ“„ **Generated Report Examples**

![SVA Generated Reports](https://github.com/KhairulIzwan/SVA/blob/main/Screenshot%202025-10-17%20093905.png)

*Example of SVA's report generation interface and sample output formats*

## ğŸ“Š Project Status & Summary

### âœ… **What Works Well**

#### **Core Functionality**
- **ğŸ¤ Speech Recognition**: Excellent accuracy with HuggingFace Whisper models
- **ğŸ‘ï¸ Object Detection**: Reliable identification of people, objects, and scenes
- **ğŸ“– Text Extraction**: Good performance on clear, readable on-screen text
- **ğŸ’¬ Chat Interface**: Smooth, responsive desktop application experience
- **ğŸ“„ Report Generation**: Professional PDF, PowerPoint, and text outputs

#### **Technical Achievements**
- **ğŸ”’ 100% Offline Operation**: No internet dependency after initial setup
- **ğŸš€ Local AI Models**: All processing using HuggingFace transformers
- **ğŸ“± Modern UI**: Tauri + React providing native desktop experience
- **ğŸ—ƒï¸ Data Persistence**: Chat history and analysis results properly stored
- **âš¡ Real-time Processing**: Live analysis feedback in chat interface

#### **User Experience**
- **ğŸ¯ Natural Language Queries**: Intuitive conversation-based interaction
- **ğŸ“Š Professional Reports**: Export-ready documents for sharing
- **ğŸ”„ Multi-format Support**: PDF, PowerPoint, and text report options
- **ğŸ“ File Management**: Organized storage of videos, chats, and reports

### âš ï¸ **Known Limitations**

#### **Content Recognition Challenges**
- **ğŸ“ Text Recognition**: Struggles with handwritten text, stylized fonts, or low-resolution content
- **ğŸ¤ Audio Quality**: Performance degrades with background noise or multiple speakers
- **ğŸŒ Language Support**: Primarily optimized for English content
- **ğŸ“ Video Length**: Processing time increases significantly with longer videos (>3 minutes)

#### **Technical Constraints**
- **ğŸ–¥ï¸ Resource Usage**: High RAM consumption during analysis (8GB+ recommended)
- **â±ï¸ Processing Speed**: Analysis can take 30-90 seconds depending on video complexity
- **ğŸ“¦ Model Size**: Initial download requires ~2GB for all AI models
- **ğŸ”§ Setup Complexity**: Multiple dependencies (Python, Node.js, Rust, FFmpeg)

#### **User Interface Areas**
- **ğŸ“‹ Report Context**: Generated reports include all analysis data, not just user-requested content
- **ğŸ”„ Session Management**: Limited ability to separate different video analyses in same chat
- **ğŸ“‚ File Upload**: Original video filenames not always preserved in processing pipeline
- **ğŸ¯ Query Specificity**: Reports don't filter content based on specific user requests

### ğŸš§ **Encountered Challenges**

#### **Integration Complexity**
- **ğŸ”— Multi-technology Stack**: Coordinating Python backend, Rust Tauri, and React frontend
- **ğŸ“¡ gRPC Communication**: Managing protocol buffers and cross-language communication
- **ğŸ—ï¸ Build Process**: Complex build pipeline with multiple compilation steps
- **ğŸ”§ Dependency Management**: Handling conflicts between Python, Node.js, and system libraries

#### **AI Model Challenges**
- **ğŸ“¥ Model Loading**: Large model files causing slow initial startup
- **ğŸ¯ Confidence Calibration**: Balancing detection sensitivity vs. false positives
- **ğŸ”€ Multi-modal Fusion**: Combining results from different AI models effectively
- **âš¡ Performance Optimization**: Balancing accuracy with processing speed

#### **Data Flow Issues**
- **ğŸ†” Session Tracking**: Maintaining context across multiple user interactions
- **ğŸ“Š Content Extraction**: Parsing complex analysis results for report generation
- **ğŸ¬ Video Processing**: Handling various video formats and resolutions consistently
- **ğŸ’¾ State Management**: Synchronizing frontend state with backend processing

### ğŸ”® **Potential Improvements**

#### **Short-term Enhancements (1-2 weeks)**
- **ğŸ¯ Context-Aware Reports**: Generate reports based on specific user queries only
- **ğŸ“‚ Better File Management**: Preserve original video filenames throughout processing
- **ğŸ”„ Session Separation**: Clear boundaries between different video analysis sessions
- **âš¡ Performance Optimization**: Implement model caching and parallel processing

#### **Medium-term Features (1-2 months)**
- **ğŸŒ Multi-language Support**: Expand beyond English for global users
- **ğŸ“Š Advanced Analytics**: Sentiment analysis, topic modeling, and content categorization
- **ğŸ¨ UI/UX Improvements**: Drag-and-drop uploads, progress indicators, batch processing
- **ğŸ“± Export Options**: Email integration, cloud save, custom report templates

#### **Long-term Vision (3-6 months)**
- **ğŸ§  Advanced AI Models**: Integration with newer, more capable models
- **ğŸ¬ Video Editing Integration**: Basic editing capabilities within the application
- **ğŸ“ˆ Analytics Dashboard**: Usage patterns, accuracy metrics, performance insights
- **ğŸ”Œ Plugin System**: Extensible architecture for custom analysis modules

### ğŸ¯ **What Could Be Achieved with More Time**

#### **With Additional 2-4 Weeks**

## ğŸ”§ Configuration

### Model Configuration
Models are automatically downloaded on first use:
- **Speech Recognition**: `openai/whisper-small`
- **Visual Text**: `microsoft/trocr-base-printed`
- **Object Detection**: `facebook/detr-resnet-50`

### Storage Locations
```
SVA/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ chat_storage/          # Chat conversations
â”‚   â”œâ”€â”€ generated_reports/     # PDF/PPT reports
â”‚   â”œâ”€â”€ uploaded_videos/       # Processed videos
â”‚   â””â”€â”€ models/               # Downloaded AI models
â””â”€â”€ frontend/
    â””â”€â”€ src-tauri/target/     # Built application
```

## ğŸ§ª Testing

### Run Backend Tests
```bash
cd backend
source ../venv/bin/activate

# Test individual components
python test_whisper.py          # Speech recognition
python vision_ai_test.py        # Object detection  
python test_transcription.py    # Text extraction
python comprehensive_test.py    # Full pipeline

# Test report generation
python -c "from mcp_servers.report_server import ReportGenerationServer; server = ReportGenerationServer(); print('âœ… Report server ready')"
```

### Frontend Testing
```bash
cd frontend
npm test                        # Run React tests
npm run tauri build --debug    # Test build process
```

## ğŸ› Troubleshooting

### Common Issues

**1. "Model download failed"**
```bash
# Clear model cache and retry
rm -rf ~/.cache/huggingface/
python test_whisper.py
```

**2. "FFmpeg not found"**
```bash
# Verify FFmpeg installation
ffmpeg -version

# On Ubuntu/Debian
sudo apt install ffmpeg

# On macOS
brew install ffmpeg
```

**3. "Permission denied on model files"**
```bash
# Fix model directory permissions
chmod -R 755 backend/models/
```

**4. "Tauri build fails"**
```bash
# Update Rust and Tauri
rustup update
npm install -g @tauri-apps/cli@latest
```

**5. "Reports not generating"**
```bash
# Check if in virtual environment
source venv/bin/activate
pip install reportlab python-pptx
```

### Performance Optimization

**For better performance:**
- Use shorter videos (< 2 minutes)
- Close other applications during analysis
- Ensure sufficient RAM (8GB minimum)
- Use SSD storage for faster model loading

### Debug Mode
```bash
# Enable detailed logging
export RUST_LOG=debug
export PYTHONPATH=$PYTHONPATH:/home/user/SVA/backend

# Run with debug output
npm run tauri dev
```

## ğŸ“ Project Structure

```
SVA/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ PROJECT_OVERVIEW.md         # Detailed project documentation
â”œâ”€â”€ backend/                    # Python AI backend
â”‚   â”œâ”€â”€ mcp_servers/           # MCP protocol servers
â”‚   â”œâ”€â”€ grpc_server_fixed_new.py  # Main gRPC server
â”‚   â”œâ”€â”€ simple_video_analyzer.py  # Core analysis engine
â”‚   â””â”€â”€ test_*.py              # Test scripts
â”œâ”€â”€ frontend/                   # Tauri + React frontend
â”‚   â”œâ”€â”€ src/                   # React components
â”‚   â”œâ”€â”€ src-tauri/            # Tauri configuration
â”‚   â””â”€â”€ package.json          # Node.js dependencies
â””â”€â”€ scripts/                   # Setup and utility scripts
    â””â”€â”€ setup.ps1             # Windows setup script
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes and test thoroughly
4. Commit: `git commit -am 'Add new feature'`
5. Push: `git push origin feature-name`
6. Create a Pull Request

## ğŸ“ License

This project is open source. See LICENSE file for details.

## ğŸ†˜ Support

- **Issues**: Report bugs on GitHub Issues
- **Documentation**: Check PROJECT_OVERVIEW.md for technical details
- **Performance**: See troubleshooting section above

---

**Built with â¤ï¸ using HuggingFace Transformers, Tauri, and React**

